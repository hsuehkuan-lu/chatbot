{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from pathlib import Path\n",
    "import json\n",
    "resume = Path('saved/models/ChatbotLSTM/30epoch/model_best.pth')\n",
    "cfg_fname = resume.parent / 'config.json'\n",
    "config = ConfigParser(json.load(open(cfg_fname, 'r')))\n",
    "config.resume = resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data loader\n",
      "ChatbotEncoder(\n",
      "  (embedding): Embedding(12055, 50, padding_idx=1)\n",
      "  (lstm): LSTM(50, 512, num_layers=2, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "Trainable parameters: 9212542\n",
      "LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(12055, 50, padding_idx=1)\n",
      "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lstm): LSTM(50, 512, num_layers=2, dropout=0.1)\n",
      "  (concat): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (out): Linear(in_features=512, out_features=12055, bias=True)\n",
      "  (attn): Attention(\n",
      "    (attn): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 11093397\n",
      "Loading checkpoint: saved/models/ChatbotLSTM/30epoch/model_best.pth ...\n",
      "GreedySearchDecoder(\n",
      "  (encoder): ChatbotEncoder(\n",
      "    (embedding): Embedding(12055, 50, padding_idx=1)\n",
      "    (lstm): LSTM(50, 512, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  )\n",
      "  (decoder): LuongAttnDecoderRNN(\n",
      "    (embedding): Embedding(12055, 50, padding_idx=1)\n",
      "    (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lstm): LSTM(50, 512, num_layers=2, dropout=0.1)\n",
      "    (concat): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (out): Linear(in_features=512, out_features=12055, bias=True)\n",
      "    (attn): Attention(\n",
      "      (attn): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 19703189\n"
     ]
    }
   ],
   "source": [
    "logger = config.get_logger('inference')\n",
    "\n",
    "# setup data_loader instances\n",
    "data_loader = config.init_obj(\n",
    "    'inference_data_loader',\n",
    "    module_data,\n",
    "    text_field_path=config.resume.parent / 'TEXT.Field',\n",
    "    vocab_path=config.resume.parent / 'TEXT.Vocab'\n",
    ")\n",
    "logger.info('Load data loader')\n",
    "\n",
    "# build model architecture\n",
    "encoder = config.init_obj(\n",
    "    'encoder_arch', module_arch,\n",
    "    vocab_size=data_loader.vocab_size,\n",
    "    padding_idx=data_loader.padding_idx,\n",
    "    hidden_size=config['hidden_size'],\n",
    "    embed_size=config['embed_size']\n",
    ")\n",
    "encoder.eval()\n",
    "logger.info(encoder)\n",
    "decoder = config.init_obj(\n",
    "    'decoder_arch', module_arch,\n",
    "    embedding=encoder.embedding,\n",
    "    embed_size=config['embed_size'],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    vocab_size=data_loader.vocab_size\n",
    ")\n",
    "decoder.eval()\n",
    "logger.info(decoder)\n",
    "model_idx = dict([('encoder', 0), ('decoder', 1)])\n",
    "models = [encoder, decoder]\n",
    "\n",
    "logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
    "checkpoint = torch.load(config.resume, map_location=torch.device('cpu'))\n",
    "for idx in range(len(models)):\n",
    "    models[idx].load_state_dict(\n",
    "        checkpoint['{}_state_dict'.format(type(models[idx]).__name__)]\n",
    "    )\n",
    "\n",
    "greedy_decoder = config.init_obj(\n",
    "    'inference_arch', module_arch,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    init_idx=data_loader.init_idx\n",
    ")\n",
    "logger.info(greedy_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input text:  can i help you\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    text = input(\"Input text: \")\n",
    "    x, x_len = data_loader.preprocess(text)\n",
    "    # print(x)\n",
    "    talk_seq = torch.ones_like(x)\n",
    "    talk_seq[0:-1], talk_seq_len = x[1:], x_len - 1\n",
    "    # x, x_len = x.to(device), x_len.to(device)\n",
    "    all_tokens, all_scores = greedy_decoder(talk_seq, talk_seq_len, data_loader.sent_len)\n",
    "    converted_text = data_loader.convert_ids_to_text(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '12', '1', 'can', 'r13']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = []\n",
    "t = ['hello', '12', '1', ',', 'can', 'r13', ':']\n",
    "for tok in t:\n",
    "    i = re.sub(r'[\\W]', '', tok)\n",
    "    if i:\n",
    "        l += [i]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
